
input {
    kafka {
        bootstrap_servers => ["broker001:9092"]
        auto_offset_reset => "latest"
        consumer_threads => 3 # 3个消费线程，默认是1个
        topics => ["log","log-collect"]
	codec => json
    }
}
	
filter {
	  grok {
   		 match => { "message" => "\A%{TIMESTAMP_ISO8601:timestamp}\s*%{DATA:app}\s\[%{WORD:TraceId}?\,%{WORD:SpanId}?,%{WORD:ParentSpanId},%{WORD:spanExport}?\]\s*.*%{LOGLEVEL:loglevel}\s*%{JAVACLASS:class}\s%{GREEDYDATA:message}\s*" }
	}

}
output {
    stdout{ codec => rubydebug } # 输出到控制台
    elasticsearch { # 输出到 Elasticsearch
        action => "index"
        hosts  => ["es001:9200"]
        index  => "logstash-%{server_name}-%{+yyyy.MM.dd}"
        document_type => "%{server_name}"
        # user => "elastic" # 如果选择开启xpack security需要输入帐号密码
        # password => "changeme"
    }
}   
