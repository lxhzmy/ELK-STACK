
input {
    kafka {
        bootstrap_servers => "broker001:9092,broker002:9092,broker003:9092"
        auto_offset_reset => "latest"
        consumer_threads => 3 # 3个消费线程，默认是1个
        topics => ["log"]
    codec => multiline {
      pattern => "^\s"
      what => "previous"
    }
    }
}
    
filter {
      grok {
         match => { "message" => "\A%{TIMESTAMP_ISO8601:timestamp}\s*%{DATA:app}\s\[%{WORD:TraceId}?\,%{WORD:SpanId}?\,%{WORD:ParentSpanId}?\,%{WORD:spanExport}?\]\s*\[(?<thread_name>.+?)\]?\s*%{LOGLEVEL:loglevel}\s*%{JAVACLASS:class}\s%{GREEDYDATA:msg}\s*" }


    }
      date {
        match=> ["timestamp","YYYY-MM-dd HH:mm:ss.SSS"]
        target=> "@timestamp"
        locale => "en"
        timezone => "+08:00"
        remove_field =>[ "timestamp","message","@version"]

    }                

}
output {
    stdout{ codec => rubydebug } # 输出到控制台
    elasticsearch { # 输出到 Elasticsearch
        action => "index"
        hosts  => ["es001:9200"]
        index  => "logstash-%{app}-%{+yyyy.MM.dd}"
        document_type => "%{app}"
        # user => "elastic" # 如果选择开启xpack security需要输入帐号密码
        # password => "changeme"
    }
}   

